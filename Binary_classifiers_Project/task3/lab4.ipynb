{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission by:\n",
    "    Name: Sarthak Punjabi\n",
    "    Student Number: 21183147\n",
    "    Module Name: CS4168 Data Mining\n",
    "    Lab Number: 1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab - 4: Comparison of Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Importing the required libraries`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline, make_pipeline, FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn. preprocessing import StandardScaler, RobustScaler, FunctionTransformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import  accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Importing the dataset `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../datasets/seeds.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Exploratory Data Analysis`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting a quick glance on the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>perimeter</th>\n",
       "      <th>compactness</th>\n",
       "      <th>length of kernel</th>\n",
       "      <th>width of kernel</th>\n",
       "      <th>asymmetry coefficient</th>\n",
       "      <th>length of kernel groove</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.26</td>\n",
       "      <td>14.84</td>\n",
       "      <td>0.8710</td>\n",
       "      <td>5.763</td>\n",
       "      <td>3.312</td>\n",
       "      <td>2.221</td>\n",
       "      <td>5.220</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.88</td>\n",
       "      <td>14.57</td>\n",
       "      <td>0.8811</td>\n",
       "      <td>5.554</td>\n",
       "      <td>3.333</td>\n",
       "      <td>1.018</td>\n",
       "      <td>4.956</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.29</td>\n",
       "      <td>14.09</td>\n",
       "      <td>0.9050</td>\n",
       "      <td>5.291</td>\n",
       "      <td>3.337</td>\n",
       "      <td>2.699</td>\n",
       "      <td>4.825</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.84</td>\n",
       "      <td>13.94</td>\n",
       "      <td>0.8955</td>\n",
       "      <td>5.324</td>\n",
       "      <td>3.379</td>\n",
       "      <td>2.259</td>\n",
       "      <td>4.805</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.14</td>\n",
       "      <td>14.99</td>\n",
       "      <td>0.9034</td>\n",
       "      <td>5.658</td>\n",
       "      <td>3.562</td>\n",
       "      <td>1.355</td>\n",
       "      <td>5.175</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14.38</td>\n",
       "      <td>14.21</td>\n",
       "      <td>0.8951</td>\n",
       "      <td>5.386</td>\n",
       "      <td>3.312</td>\n",
       "      <td>2.462</td>\n",
       "      <td>4.956</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14.69</td>\n",
       "      <td>14.49</td>\n",
       "      <td>0.8799</td>\n",
       "      <td>5.563</td>\n",
       "      <td>3.259</td>\n",
       "      <td>3.586</td>\n",
       "      <td>5.219</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14.11</td>\n",
       "      <td>14.10</td>\n",
       "      <td>0.8911</td>\n",
       "      <td>5.420</td>\n",
       "      <td>3.302</td>\n",
       "      <td>2.700</td>\n",
       "      <td>5.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>16.63</td>\n",
       "      <td>15.46</td>\n",
       "      <td>0.8747</td>\n",
       "      <td>6.053</td>\n",
       "      <td>3.465</td>\n",
       "      <td>2.040</td>\n",
       "      <td>5.877</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>16.44</td>\n",
       "      <td>15.25</td>\n",
       "      <td>0.8880</td>\n",
       "      <td>5.884</td>\n",
       "      <td>3.505</td>\n",
       "      <td>1.969</td>\n",
       "      <td>5.533</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    area  perimeter  compactness  length of kernel  width of kernel  \\\n",
       "0  15.26      14.84       0.8710             5.763            3.312   \n",
       "1  14.88      14.57       0.8811             5.554            3.333   \n",
       "2  14.29      14.09       0.9050             5.291            3.337   \n",
       "3  13.84      13.94       0.8955             5.324            3.379   \n",
       "4  16.14      14.99       0.9034             5.658            3.562   \n",
       "5  14.38      14.21       0.8951             5.386            3.312   \n",
       "6  14.69      14.49       0.8799             5.563            3.259   \n",
       "7  14.11      14.10       0.8911             5.420            3.302   \n",
       "8  16.63      15.46       0.8747             6.053            3.465   \n",
       "9  16.44      15.25       0.8880             5.884            3.505   \n",
       "\n",
       "   asymmetry coefficient  length of kernel groove  type  \n",
       "0                  2.221                    5.220     1  \n",
       "1                  1.018                    4.956     1  \n",
       "2                  2.699                    4.825     1  \n",
       "3                  2.259                    4.805     1  \n",
       "4                  1.355                    5.175     1  \n",
       "5                  2.462                    4.956     1  \n",
       "6                  3.586                    5.219     1  \n",
       "7                  2.700                    5.000     1  \n",
       "8                  2.040                    5.877     1  \n",
       "9                  1.969                    5.533     1  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>perimeter</th>\n",
       "      <th>compactness</th>\n",
       "      <th>length of kernel</th>\n",
       "      <th>width of kernel</th>\n",
       "      <th>asymmetry coefficient</th>\n",
       "      <th>length of kernel groove</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>12.38</td>\n",
       "      <td>13.44</td>\n",
       "      <td>0.8609</td>\n",
       "      <td>5.219</td>\n",
       "      <td>2.989</td>\n",
       "      <td>5.472</td>\n",
       "      <td>5.045</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>12.67</td>\n",
       "      <td>13.32</td>\n",
       "      <td>0.8977</td>\n",
       "      <td>4.984</td>\n",
       "      <td>3.135</td>\n",
       "      <td>2.300</td>\n",
       "      <td>4.745</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>11.18</td>\n",
       "      <td>12.72</td>\n",
       "      <td>0.8680</td>\n",
       "      <td>5.009</td>\n",
       "      <td>2.810</td>\n",
       "      <td>4.051</td>\n",
       "      <td>4.828</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>12.70</td>\n",
       "      <td>13.41</td>\n",
       "      <td>0.8874</td>\n",
       "      <td>5.183</td>\n",
       "      <td>3.091</td>\n",
       "      <td>8.456</td>\n",
       "      <td>5.000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>12.37</td>\n",
       "      <td>13.47</td>\n",
       "      <td>0.8567</td>\n",
       "      <td>5.204</td>\n",
       "      <td>2.960</td>\n",
       "      <td>3.919</td>\n",
       "      <td>5.001</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>12.19</td>\n",
       "      <td>13.20</td>\n",
       "      <td>0.8783</td>\n",
       "      <td>5.137</td>\n",
       "      <td>2.981</td>\n",
       "      <td>3.631</td>\n",
       "      <td>4.870</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>11.23</td>\n",
       "      <td>12.88</td>\n",
       "      <td>0.8511</td>\n",
       "      <td>5.140</td>\n",
       "      <td>2.795</td>\n",
       "      <td>4.325</td>\n",
       "      <td>5.003</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>13.20</td>\n",
       "      <td>13.66</td>\n",
       "      <td>0.8883</td>\n",
       "      <td>5.236</td>\n",
       "      <td>3.232</td>\n",
       "      <td>8.315</td>\n",
       "      <td>5.056</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>11.84</td>\n",
       "      <td>13.21</td>\n",
       "      <td>0.8521</td>\n",
       "      <td>5.175</td>\n",
       "      <td>2.836</td>\n",
       "      <td>3.598</td>\n",
       "      <td>5.044</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>12.30</td>\n",
       "      <td>13.34</td>\n",
       "      <td>0.8684</td>\n",
       "      <td>5.243</td>\n",
       "      <td>2.974</td>\n",
       "      <td>5.637</td>\n",
       "      <td>5.063</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      area  perimeter  compactness  length of kernel  width of kernel  \\\n",
       "200  12.38      13.44       0.8609             5.219            2.989   \n",
       "201  12.67      13.32       0.8977             4.984            3.135   \n",
       "202  11.18      12.72       0.8680             5.009            2.810   \n",
       "203  12.70      13.41       0.8874             5.183            3.091   \n",
       "204  12.37      13.47       0.8567             5.204            2.960   \n",
       "205  12.19      13.20       0.8783             5.137            2.981   \n",
       "206  11.23      12.88       0.8511             5.140            2.795   \n",
       "207  13.20      13.66       0.8883             5.236            3.232   \n",
       "208  11.84      13.21       0.8521             5.175            2.836   \n",
       "209  12.30      13.34       0.8684             5.243            2.974   \n",
       "\n",
       "     asymmetry coefficient  length of kernel groove  type  \n",
       "200                  5.472                    5.045     3  \n",
       "201                  2.300                    4.745     3  \n",
       "202                  4.051                    4.828     3  \n",
       "203                  8.456                    5.000     3  \n",
       "204                  3.919                    5.001     3  \n",
       "205                  3.631                    4.870     3  \n",
       "206                  4.325                    5.003     3  \n",
       "207                  8.315                    5.056     3  \n",
       "208                  3.598                    5.044     3  \n",
       "209                  5.637                    5.063     3  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here we can see that there are no missing values so we can skip the missing value data preparation step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>perimeter</th>\n",
       "      <th>compactness</th>\n",
       "      <th>length of kernel</th>\n",
       "      <th>width of kernel</th>\n",
       "      <th>asymmetry coefficient</th>\n",
       "      <th>length of kernel groove</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>210.000000</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>210.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14.847524</td>\n",
       "      <td>14.559286</td>\n",
       "      <td>0.870999</td>\n",
       "      <td>5.628533</td>\n",
       "      <td>3.258605</td>\n",
       "      <td>3.700201</td>\n",
       "      <td>5.408071</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.909699</td>\n",
       "      <td>1.305959</td>\n",
       "      <td>0.023629</td>\n",
       "      <td>0.443063</td>\n",
       "      <td>0.377714</td>\n",
       "      <td>1.503557</td>\n",
       "      <td>0.491480</td>\n",
       "      <td>0.818448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>10.590000</td>\n",
       "      <td>12.410000</td>\n",
       "      <td>0.808100</td>\n",
       "      <td>4.899000</td>\n",
       "      <td>2.630000</td>\n",
       "      <td>0.765100</td>\n",
       "      <td>4.519000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>12.270000</td>\n",
       "      <td>13.450000</td>\n",
       "      <td>0.856900</td>\n",
       "      <td>5.262250</td>\n",
       "      <td>2.944000</td>\n",
       "      <td>2.561500</td>\n",
       "      <td>5.045000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>14.355000</td>\n",
       "      <td>14.320000</td>\n",
       "      <td>0.873450</td>\n",
       "      <td>5.523500</td>\n",
       "      <td>3.237000</td>\n",
       "      <td>3.599000</td>\n",
       "      <td>5.223000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>17.305000</td>\n",
       "      <td>15.715000</td>\n",
       "      <td>0.887775</td>\n",
       "      <td>5.979750</td>\n",
       "      <td>3.561750</td>\n",
       "      <td>4.768750</td>\n",
       "      <td>5.877000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>21.180000</td>\n",
       "      <td>17.250000</td>\n",
       "      <td>0.918300</td>\n",
       "      <td>6.675000</td>\n",
       "      <td>4.033000</td>\n",
       "      <td>8.456000</td>\n",
       "      <td>6.550000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             area   perimeter  compactness  length of kernel  width of kernel  \\\n",
       "count  210.000000  210.000000   210.000000        210.000000       210.000000   \n",
       "mean    14.847524   14.559286     0.870999          5.628533         3.258605   \n",
       "std      2.909699    1.305959     0.023629          0.443063         0.377714   \n",
       "min     10.590000   12.410000     0.808100          4.899000         2.630000   \n",
       "25%     12.270000   13.450000     0.856900          5.262250         2.944000   \n",
       "50%     14.355000   14.320000     0.873450          5.523500         3.237000   \n",
       "75%     17.305000   15.715000     0.887775          5.979750         3.561750   \n",
       "max     21.180000   17.250000     0.918300          6.675000         4.033000   \n",
       "\n",
       "       asymmetry coefficient  length of kernel groove        type  \n",
       "count             210.000000               210.000000  210.000000  \n",
       "mean                3.700201                 5.408071    2.000000  \n",
       "std                 1.503557                 0.491480    0.818448  \n",
       "min                 0.765100                 4.519000    1.000000  \n",
       "25%                 2.561500                 5.045000    1.000000  \n",
       "50%                 3.599000                 5.223000    2.000000  \n",
       "75%                 4.768750                 5.877000    3.000000  \n",
       "max                 8.456000                 6.550000    3.000000  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the dataset does not contain any null values, which makes it easier to deal with and cuts down on the preprocessing time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "area                       0\n",
       "perimeter                  0\n",
       "compactness                0\n",
       "length of kernel           0\n",
       "width of kernel            0\n",
       "asymmetry coefficient      0\n",
       "length of kernel groove    0\n",
       "type                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we check if there are any values that are zero in the dataset that can be useless and might make the prediction algorithms not work the way it is supposed to be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df.values == 0).any(axis=1)].index.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we calculate the distribution of the dataset into the three different parts in the target variable being \"type\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    70\n",
       "2    70\n",
       "3    70\n",
       "Name: type, dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"type\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we visualise the variables by box plot to have a look at the outliers that we have in order to include the outlier handling process to the entire process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.loc[:, :\"length of kernel groove\"].boxplot(figsize=(20, 5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will attempt training SVM, Random Forest, and K-Nearest Neighbor classifiers. We will tune their parameters, compare them and choose the best classifier for our problem. Here we will prepare a scikit-learn pipeline for data preparation (preprocessing pipeline), which we will apply later. The use of his pipelines ensures that preprocessing is applied separately to any training validation and test dataset without data leakage.\n",
    "\n",
    "First, we need to prepare two lists of column names. The list `names_outliers` contains the names of the three columns to which we will apply log transformation followed by `RobustScaler`. The list `names_no_outliers` contains the names of all other predictor columns to which we will apply `StandardScaler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store a list with the names of all predictors\n",
    "names_all = [c for c in df if c not in [\"type\"]]\n",
    "\n",
    "# define column groups with same data preparation\n",
    "names_outliers = [\"area\", \"perimeter\", \"compactness\"]\n",
    "names_no_outliers = list(set(names_all) - set(names_outliers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddColumnNames(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return pd.DataFrame(data=X, columns=self.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        assert isinstance(X, pd.DataFrame)\n",
    "        return X[self.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_pipeline = make_pipeline(\n",
    "    AddColumnNames(columns=names_all),\n",
    "    FeatureUnion(transformer_list=[\n",
    "        (\"outlier_columns\", make_pipeline(\n",
    "            ColumnSelector(columns=names_outliers),\n",
    "            FunctionTransformer(np.log, validate=True),\n",
    "            RobustScaler()\n",
    "        )),\n",
    "        (\"no_outlier_columns\", make_pipeline(\n",
    "            ColumnSelector(columns=names_no_outliers),\n",
    "            StandardScaler()\n",
    "        ))\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we separate the columns into target and predictor and then split the dataset into training and testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['type']\n",
    "X = df.drop('type', axis=1).values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameter `stratify=y` ensures that the classes are represented in the same proportion in both the training and the test sets.\n",
    "\n",
    "Note that after the split into a training and test sets, X_train and X_test are numpy arrays and no longer have column names. That's why we needed the class above to put the names of columns back in the preprocessing pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search for Best Parameters of Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we train an SVM classifier with the training set and a range of possible parameters in order to find the best parameters for SVM by cross-validation. To do this we will build another pipeline which includes the preprocessing pipeline and the SVM classifier. The pipeline will take care for separately preprocessing the training and validation sets after the training set is further split into training and validation sets in the process of cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV score = 0.947:\n",
      "Best parameters:  {'svm__C': 100, 'svm__gamma': 0.01, 'svm__kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "# create the pipeline\n",
    "pipe = Pipeline(steps=[('preprocess', preprocess_pipeline), ('svm', svm.SVC(probability=True))])\n",
    "\n",
    "# prepare a prameter grid\n",
    "# note that __ can be used to specify the name of a parameter for a specific element in a pipeline\n",
    "# note also that this is not an exhaustive list of the parameters of svn.SVC and their possible values\n",
    "\n",
    "param_grid = {\n",
    "    'svm__C': [0.1, 1, 10, 100],  \n",
    "    'svm__gamma': [1, 0.1, 0.01, 0.001], \n",
    "    'svm__kernel': ['rbf', 'linear', 'poly']}\n",
    "\n",
    "search = GridSearchCV(pipe, param_grid, n_jobs=-1, cv=5, refit=True)\n",
    "search.fit(X_train, y_train) #trainign happens here! SVM is trained 240 times\n",
    "\n",
    "print(\"Best CV score = %0.3f:\" % search.best_score_)\n",
    "print(\"Best parameters: \", search.best_params_)\n",
    "\n",
    "# store the best params and best model for later use\n",
    "SVM_best_params = search.best_params_\n",
    "SVM_best_model = search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we train an Random Forest classifier with the training set and a range of possible parameters in order to find the best parameters. To do this we will build another pipeline which includes the preprocessing pipeline and the Random Forest classifier. The pipeline will take care for separately preprocessing the training and validation sets after the training set is further split into training and validation sets in the process of cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV score = 0.941:\n",
      "Best parameters:  {'rf__max_depth': 8, 'rf__n_estimators': 30}\n"
     ]
    }
   ],
   "source": [
    "# create the pipeline\n",
    "pipe = Pipeline(steps=[('preprocess', preprocess_pipeline), ('rf', RandomForestClassifier())])\n",
    "\n",
    "# prepare a prameter grid\n",
    "# note that __ can be used to specify the name of a parameter for a specific element in a pipeline\n",
    "# note also that this is not an exhaustive list of the parameters of RandomForestClassifier and their possible values\n",
    "param_grid = {\n",
    "    'rf__n_estimators' : [10,20,30],\n",
    "    'rf__max_depth': [2, 4, 6, 8]\n",
    "}\n",
    "\n",
    "search = GridSearchCV(pipe, param_grid, n_jobs=-1, cv=5, refit=True)\n",
    "search.fit(X_train, y_train)\n",
    "print(\"Best CV score = %0.3f:\" % search.best_score_)\n",
    "print(\"Best parameters: \", search.best_params_)\n",
    "\n",
    "# store the best params and best model for later use\n",
    "RF_best_params = search.best_params_\n",
    "RF_best_model = search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we train an K-Nearest Neighbor classifier with the training set and a range of possible parameters in order to find the best parameters. To do this we will build another pipeline which includes the preprocessing pipeline and the K-Nearest Neighbor classifier. The pipeline will take care for separately preprocessing the training and validation sets after the training set is further split into training and validation sets in the process of cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV score = 0.929:\n",
      "Best parameters:  {'knn__algorithm': 'ball_tree', 'knn__n_neighbors': 10}\n"
     ]
    }
   ],
   "source": [
    "# create the pipeline\n",
    "pipe = Pipeline(steps=[('preprocess', preprocess_pipeline), ('knn', KNeighborsClassifier())])\n",
    "\n",
    "# prepare a prameter grid\n",
    "# note that __ can be used to specify the name of a parameter for a specific element in a pipeline\n",
    "# note also that this is not an exhaustive list of the parameters of RandomForestClassifier and their possible values\n",
    "param_grid = {\n",
    "    'knn__n_neighbors' : [10,20,30],\n",
    "    'knn__algorithm': [\"ball_tree\", \"kd_tree\", \"brute\"]\n",
    "}\n",
    "\n",
    "search = GridSearchCV(pipe, param_grid, n_jobs=-1, cv=5, refit=True)\n",
    "search.fit(X_train, y_train)\n",
    "print(\"Best CV score = %0.3f:\" % search.best_score_)\n",
    "print(\"Best parameters: \", search.best_params_)\n",
    "\n",
    "# store the best params and best model for later use\n",
    "knn_best_params = search.best_params_\n",
    "knn_best_model = search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can evaluate the best models found by the grid search on the test dataset and compare their results (accuracy, precision, recall, etc.) to choose the better classifier for our problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The evaluation function below evaluates a model on a test data set. Note that, the preprocessing pipeline will be automatically applied to the test set. The results returned by the function are a variety of metrics measured on the test set which we will use to compare the models and decide which classifier to choose for training the final model. These metrics are:\n",
    "\n",
    "- accuracy\n",
    "- precisions\n",
    "- recall\n",
    "- F1-score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Classifiers on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_fpr = np.linspace(start=0, stop=1, num=100)\n",
    "# model - a trained binary probabilistic classification model;\n",
    "#         it is assumed that there are two classes: 0 and 1\n",
    "#         and the classifier learns to predict probabilities for the examples to belong to class 1\n",
    "\n",
    "def evaluate_model(X_test, y_test, model):\n",
    "    # compute probabilistic predictiond for the evaluation set\n",
    "    _probabilities = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # compute exact predictiond for the evaluation set\n",
    "    _predicted_values = model.predict(X_test)\n",
    "        \n",
    "    # compute accuracy\n",
    "    _accuracy = accuracy_score(y_test, _predicted_values)\n",
    "        \n",
    "    # compute precision, recall and f1 score for class 1\n",
    "    _precision, _recall, _f1_score, _ = precision_recall_fscore_support(y_test, _predicted_values, labels=[1])\n",
    "            \n",
    "    return _accuracy, _precision[0], _recall[0], _f1_score[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_accuracy, SVM_precision, SVM_recall, SVM_f1_score = evaluate_model(X_test, y_test, SVM_best_model)\n",
    "RF_accuracy, RF_precision, RF_recall, RF_f1_score = evaluate_model(X_test, y_test, RF_best_model)\n",
    "knn_accuracy, knn_precision, knn_recall, knn_f1_score = evaluate_model(X_test, y_test, knn_best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "SVM_metrics = np.array([SVM_accuracy, SVM_precision, SVM_recall, SVM_f1_score])\n",
    "RF_metrics = np.array([RF_accuracy, RF_precision, RF_recall, RF_f1_score])\n",
    "knn_metrics = np.array([knn_accuracy, knn_precision, knn_recall, knn_f1_score])\n",
    "index = ['accuracy', 'precision', 'recall', 'F1-score']\n",
    "df_metrics = pd.DataFrame({'SVM': SVM_metrics, 'Random Forest': RF_metrics, 'K Nearest Neighbor': knn_metrics}, index=index)\n",
    "df_metrics.plot.bar(rot=0)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a Final Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can train an SVM model with all data we have, assuming that the more data we have the better the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to remove the string 'svm__' from the names of the parameters in SVM_best_params\n",
    "def transform(dict):\n",
    "    return {key.replace('svm__','') :  value for key, value in dict.items()}\n",
    "\n",
    "pipe = make_pipeline(preprocess_pipeline, svm.SVC(**transform(SVM_best_params)))\n",
    "\n",
    "final_model =pipe.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'final_model.sav'\n",
    "pickle.dump(final_model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
